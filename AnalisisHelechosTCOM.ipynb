{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2ttzNtwebvtLdgISnydli",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NDGC14/proj-bases-3/blob/main/AnalisisHelechosTCOM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bibJpM_pOjB8",
        "outputId": "e65e2355-dc57-44ee-ef8c-f4b46630ffc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
            "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
            "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.2\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 4.0.0     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.3.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.1.0     \n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
          ]
        }
      ],
      "source": [
        "#LOAD UP NECESSARY R LIBRARIES\n",
        "library (tidyverse)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD UP FILE, IGNORE METADATA\n",
        "data <- read_csv(\"FILEPATH\", skip = 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "yxfwXrhFPAwe",
        "outputId": "9922a67f-3109-4a39-a146-50ad1597d540"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error: 'FILEPATH' does not exist in current working directory ('/content').\n",
          "traceback": [
            "Error: 'FILEPATH' does not exist in current working directory ('/content').\nTraceback:\n",
            "1. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
            "2. vroom_(file, delim = delim %||% col_types$delim, col_names = col_names, \n .     col_types = col_types, id = id, skip = skip, col_select = col_select, \n .     name_repair = .name_repair, na = na, quote = quote, trim_ws = trim_ws, \n .     escape_double = escape_double, escape_backslash = escape_backslash, \n .     comment = comment, skip_empty_rows = skip_empty_rows, locale = locale, \n .     guess_max = guess_max, n_max = n_max, altrep = vroom_altrep(altrep), \n .     num_threads = num_threads, progress = progress)",
            "3. (function (path, write = FALSE) \n . {\n .     if (is.raw(path)) {\n .         return(rawConnection(path, \"rb\"))\n .     }\n .     if (!is.character(path)) {\n .         return(path)\n .     }\n .     if (is_url(path)) {\n .         if (requireNamespace(\"curl\", quietly = TRUE)) {\n .             con <- curl::curl(path)\n .         }\n .         else {\n .             inform(\"`curl` package not installed, falling back to using `url()`\")\n .             con <- url(path)\n .         }\n .         ext <- tolower(tools::file_ext(path))\n .         return(switch(ext, zip = , bz2 = , xz = {\n .             close(con)\n .             stop(\"Reading from remote `\", ext, \"` compressed files is not supported,\\n\", \n .                 \"  download the files locally first.\", call. = FALSE)\n .         }, gz = gzcon(con), con))\n .     }\n .     path <- enc2utf8(path)\n .     p <- split_path_ext(basename_utf8(path))\n .     if (write) {\n .         path <- normalizePath_utf8(path, mustWork = FALSE)\n .     }\n .     else {\n .         path <- check_path(path)\n .     }\n .     if (is_installed(\"archive\")) {\n .         formats <- archive_formats(p$extension)\n .         extension <- p$extension\n .         while (is.null(formats) && nzchar(extension)) {\n .             extension <- split_path_ext(extension)$extension\n .             formats <- archive_formats(extension)\n .         }\n .         if (!is.null(formats)) {\n .             p$extension <- extension\n .             if (write) {\n .                 if (is.null(formats[[1]])) {\n .                   return(archive::file_write(path, filter = formats[[2]]))\n .                 }\n .                 return(archive::archive_write(path, p$path, format = formats[[1]], \n .                   filter = formats[[2]]))\n .             }\n .             if (is.null(formats[[1]])) {\n .                 return(archive::file_read(path, filter = formats[[2]]))\n .             }\n .             return(archive::archive_read(path, format = formats[[1]], \n .                 filter = formats[[2]]))\n .         }\n .     }\n .     if (!write) {\n .         compression <- detect_compression(path)\n .     }\n .     else {\n .         compression <- NA\n .     }\n .     if (is.na(compression)) {\n .         compression <- tools::file_ext(path)\n .     }\n .     if (write && compression == \"zip\") {\n .         stop(\"Can only read from, not write to, .zip\", call. = FALSE)\n .     }\n .     switch(compression, gz = gzfile(path, \"\"), bz2 = bzfile(path, \n .         \"\"), xz = xzfile(path, \"\"), zip = zipfile(path, \"\"), \n .         if (!has_trailing_newline(path)) {\n .             file(path)\n .         } else {\n .             path\n .         })\n . })(\"FILEPATH\")",
            "4. check_path(path)",
            "5. stop(\"'\", path, \"' does not exist\", if (!is_absolute_path(path)) {\n .     paste0(\" in current working directory ('\", getwd(), \"')\")\n . }, \".\", call. = FALSE)",
            "6. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"'FILEPATH' does not exist in current working directory ('/content').\", \n .     base::quote(NULL))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3Rh2X4tTBDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}